{"pages":[{"title":"关于","text":"关于我一名普通的学生。","link":"/about/index.html"}],"posts":[{"title":"CSAPP第七章Linking","text":"Object FilesObject file 有三种形式 Relocatable object file Executable object file Shared object file Relocatable Object FilesCSAPP 书中选取的是ELF格式。ELF从16字节的序列作为起始，这16字节规定了字的大小和机器的字节顺序(大端或者小端)，ELH header剩下的内容帮助连接器分析解释这个object file。而各种sections的信息，如位置和大小，由section header table 给出，它包含了每个sections固定大小的入口。 sections的类型 .te xt编译后的机器码 .rodata只读数据，例如printf中的format strings 或者switch的jump tables .data初始化的全局和静态变量 .bss未初始化的全局和静态变量，并且这个section并不占据object file的实际磁盘空间，当程序运行时，这些变量会申请内存并初始化为0 .symtabsymbol table，包含了函数和全局变量的信息。 .rel.rext是.text section中需要重定位的位置的列表，例如外部函数或者外部的局部变量。和并不包含没有用到的指令。 .rel.data包含这个object module中定义或者引用的全局变量的重定位信息。 .debugdebugging symbol，只有用了-g选项编译才会产生 .line .strtab字符串表","link":"/2021/09/16/CSAPP%E7%AC%AC%E4%B8%83%E7%AB%A0Linking/"},{"title":"《STL源码剖析》第二章问题杂烩","text":"近期开始阅读侯捷《STL源码剖析》，第二章有许许多多我遇到的问题，在此汇总一下 Placement new书中的使用 语法new的语法中有placement_params可选参数，当传递给new这个参数时，就是placement_new 作用placement_new就是直接将一块内存空间指定给new，new直接在这些内存上执行构造 样例1234567891011121314//样例1void* operator new(std::size_t, void*)//样例2// within any block scope...{ alignas(T) unsigned char buf[sizeof(T)]; // Statically allocate the storage with automatic storage duration // which is large enough for any object of type `T`. T* tptr = new(buf) T; // Construct a `T` object, placing it directly into your // pre-allocated storage at memory address `buf`. tptr-&gt;~T(); // You must **manually** call the object's destructor // if its side effects is depended by the program.} // Leaving this block scope automatically deallocates `buf`. false_type和true_type书中的使用书中是用来方便__destory_aux的调用，个人理解为重载，可以由__destroy直接调用两个不同作用的函数，通过false_type和true_type这两个不同的变量类型。 未完待续….","link":"/2021/08/18/STL%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90%E7%AC%AC%E4%BA%8C%E7%AB%A0%E9%97%AE%E9%A2%98%E6%9D%82%E7%83%A9/"},{"title":"Streaming Graph Neural Networks笔记","text":"Streaming Graph Neural Networks笔记 该论文提出了DGNN模型 The update componentinteract unit$$ e(t)=act(W_1 \\cdot u_{v_s}(t-)+W_2 \\cdot u_{v_g}(t-)+b_e)$$ 其中$u_{v_s}和$u_{v_g}是点在时间t之前的特征，$W_1$和$W2$以及$b_e$是神经网络的参数,$act(\\cdot)$是激活函数。$e(t)$包含了${v_s, v_g, t}$的交互的信息。 update unitupdata unit将经过intercact unit的节点信息更新。当许多interactions作用于同一节点时，update unit将遗忘以前的interactions。这操作和LSTM很像，所以论文魔改了LSTM其中target node和source node是用的两个不同的update unit，结构相同，参数不同。update unit和LSTM不同的地方在蓝色虚线中，相当于改变了LSTM中$C$的输入。公式：$$C^I_v(t-1) = tanh(W_d \\cdot C_v(t-1)+b_d)$$ $$\\hat{C}^I_v(t-1)=C^I_v(t-1)*g(\\Delta t)$$ $$C^T_v(t-1)=C_v(t-1)-C^I_v(t-1)$$ $$C^*_v(t-1)=C^T_v(t-1)+\\hat{C}^I_v(t-1)$$其中$C^I_v$由神经网络生成，代表短期记忆，短期记忆会随着时间遗忘，所以短期记忆会乘上$g(\\Delta t)$ 得出$\\hat{C}^I_v$，来表示遗忘后的短期记忆，$g(\\Delta t)$是遗忘函数，$\\Delta t$越长，其值越小。$C^T_v$是长期记忆，值不随时间而改变。$C^*_v(t-1)$是调整之后的$C$，作为标准LSTM的输入。后面就是LSTM的内容了。$$ f_t=\\delta(W_f \\cdot e(t) + U_f \\cdot h_v(t-1)+b_f) $$$$i_t=\\delta (W_i \\cdot e(t) + U_i \\cdot h_v(t-1)+b_i)$$$$o_t = \\delta (W_o \\cdot e(t) + U_o \\cdot h_v(t-1)+b_o)$$$$\\tilde{C}(t)=tanh(W_c \\cdot e(t) +U_c \\cdot h_v(t-1)+b_c)$$$$C_v(t)=f_t * C^*_v(t-1)+i_t *\\tilde{C}_v(t)$$$$ h_v(t) = o_t * tanh(C_v(t))$$ 值得注意的是，target和source node是用了两个不同的update unit。source update 只更新source node，同理target update The merge unit该unit是将当前生成的信息与之前的信息融合，形成$u_v(t)$source node 公式：$$u_{v_s}(t) = W^S \\cdot h^S_{v_s}+W^g \\cdot h^g_{v_s}(t-)+b_u$$同理target node:$$u_{v_g}(t)=W^S*h^S_{v_g}(t-)+W^g \\cdot h^g_{v_g}(t) +b_u$$ 整个update component 的流程： The propagation componentupdate component 只考虑连接建立起来时，两点的相互作用，而propagation component 则是将这两点的交互信息带入邻居节点中。影响邻居节点的方式不是像update component 那样修改cell memory的历史，而是给cell memory增添新的信息。 符号表示$N^S(\\cdot)$表示该点的source邻居的集合，$N^g(v_g)$表示该点target邻居的集合。$$N(v_s)=N^s(v_s) \\cup N^g(v_s)$$$$N(v_g)=N^s(v_g) \\cup N^g(v_g)$$ prop unit四种类型 source node $v_s$到它的source邻居$N^s(v_s)$ source ndoe $v_s$到它的target邻居$N^g(v_s)$ target node $v_g$到它的source邻居$N^s(v_g)$ target node $v_g$到它的target邻居$N^g(v_g)$ 这四种类型的prop unit结构相同，参数不同。在论文中只提供了第一种的描述，其他类型类比即可。 propagate interaction information forrmulations$$C^s_{v_x}(t)=C^s_{v_x}(t-)+f_a(u_{v_x}(t-), u_{v_s}(t-))\\cdot g(\\Delta ^s_t) \\cdot h(\\Delta ^s_t) \\cdot \\hat{W}^s_s \\cdot e(t)$$$$h^s_{v_x}(t)=tanh(C^s_{v_x}(t))$$其中$v_x\\in N^s(v_s)$，而$\\Delta^s_t=t-tx$代表了当前时间$t$与节点$v_x$与节点$v_s$发生交互的时间$t_x$的时间间隔。$f_a$是和update component中定义$f_a$是同一个衰减函数。$W^s_s$是传给source邻居交互信息的线性变换。 函数h的定义$$h(\\Delta ^s_t)=\\begin{cases}1, \\Delta^s_t\\le \\tau,\\0, otherwise.\\end{cases}$$$\\tau$是一个超参，如果时间间隔大于这个值，那么就代表时间间隔太大了。我们就不会向这个点传递交互信息。 $f_a$的定义$f_a$是捕获$v_s$和$v_x$之间连接强度的注意力函数$$f_a(u_{v_x}(t-),u_{v_s}(t-))=\\dfrac{exp(u_{v_x}(t-)^Tu_{v_s}(t-))}{\\sum_{v\\in N^s(v_s)} exp(u_v(t-)^Tu_{v_s}(t-))}$$ propagation流程图 参数学习Parameter learning for link predictionlink prediction 就是预测下一个连接关系。 projection matrixprojection matrix $P$是关于因变量(?英文名为response values)和预测值的映射。$$\\hat{y} = Py$$ $u^s_{v_s}(t-)$和$u^g_{v_g}(t-)$论文中将$u_{v_s}(t-)和$u_{v_g}$通过$P$投射到$u^s_{v_s}(t-)$和$u^g_{v_g}(t-)$ $$u^s_{v_s}(t-)=P^s \\cdot u_{v_s}(t-)$$$$u^g_{v_g}(t-)=P^g \\cdot u_{v_g}(t-)$$ loss function对于$v_s$和$v_g$出现的概率，用$$\\sigma (u^s_{v_s}(t-)^T u^g_{v_g}(t-)) $$$\\sigma(\\cdot)$代表sigmod函数。loss function: $$ J((v_s, v_g, t))=-log(\\sigma (u^s_{v_s}(t-)^T u^g_{v_g}(t-)))-Q \\cdot \\mathbb{E}{v_n\\sim P_n(v)}log(\\sigma (u^s{v_s}(t-)^T u^g_{v_g}(t-)) )$$ $Q$是负采样的数量，$P_n{v}$是一个负采样的分布。 total loss: $$ \\sum_{e\\in \\mathcal{E}(T)}J(e) $$ 其中$\\mathcal{E}(T)$代表时间$T$之前的所有交互。 训练方法采用mini-batch进行优化，并且mini-batch中边的样本是通过交互的时间序列采样的。mini-batch的loss通过所有在其中的交互计算的。负采样的分布$P_n(v)$是一个在mini-batch外所有点的标准分布，包括了交互的点和受影响的点。","link":"/2021/09/18/Streaming-Graph-Neural-Networks%E7%AC%94%E8%AE%B0/"},{"title":"《STL源码剖析》中void (* set_malloc_handler(void (*f)()))()分析","text":"问题在阅读《STL源码剖析》的时候，遇到了这么一个函数 先不说函数的意思，函数的形式我就没看懂…好多好多括号… 函数指针函数指针就是指向函数的指针… 1234567891011121314151617181920212223242526272829/* 例一：函式指標直接呼叫 复制自WIKI*/# ifndef __cplusplus # include &lt;stdio.h&gt;# else # include &lt;cstdio&gt;# endifint max(int x, int y){ return x &gt; y ? x : y;}int main(void){ /* p 是函数指针*/ int (* p)(int, int) = &amp; max; // &amp;可以省略 int a, b, c, d; printf(&quot;please input 3 numbers:&quot;); scanf(&quot;%d %d %d&quot;, &amp; a, &amp; b, &amp; c); /* 與直接呼叫函式等價，d = max(max(a, b), c) */ d = p(p(a, b), c); printf(&quot;the maxumum number is: %d\\n&quot;, d); return 0;} 在《STL源码剖析》里的这个函数，实际上使用了函数指针作为参数 1void (*f)() 函数指针作为返回值1int (*test(int))(int, int) 阅读方法是由内向外读，首先test有形参列表，所以是一个函数，并且参数只需要一个int，然后test的前面有一个*，所以返回一个指针，(*test(int))作为一个指针，有形参列表(int, int)，所以这个指针指向函数，并且这个函数返回int类型的值。 分析1void (* set_malloc_handler(void (*f)()))() 首先，set_malloc_handler作为函数名，有一个形参，是void(*f)()，void(f)()是一个函数指针类型，指向返回值为void，参数为空的函数。这说明set_malloc_handler是函数，并且前面有，所以要返回指针，指针后面接着形参列表，为空()，说明是指向函数的指针，并且指向的函数返回类型为void。","link":"/2021/08/20/%E5%87%BD%E6%95%B0%E6%8C%87%E9%92%88/"},{"title":"动态图神经网络综述笔记(一)分类","text":"本文是动态网络综述：Foundations and modelling of dynamicnetworks using Dynamic Graph NeuralNetworks: A survey 的笔记 分类根据时间粒度分类 Static没有时间信息 Edge-weighted时间信息被当做标签存放在静态网络的边/点中，最直观的例子是静态网络中边最后一次活跃时间的标签。 Discretue以离散的时间间隔表示时间信息，可以用不同时间间隔的快照来表示。 Continuous没有时间间隔，这种表示方式承载着最多的信息，但同时也最复杂。 后两者主要用来建立动态网络。 表示方法 Discrete RepresentationT代表快照的序号 Continuous Representation The event-basedrepresentationui和vi是一对连接的点，ti是时间戳，代表连接开始的时间，△i是事件(连接)持续的时间 The contact sequence representation是上一种的简化，在这种连接中，连接是instantaneous(瞬时)的，所以没有连接的持续时间。 The graph stream representation其中 ui,vi是一对连接的点，ti是事件发生的时间，最后的符号如果为1，代表边的的加入，-1代表边的删除。 根据连接时间分类 Interaction Temporal Evolving Strictly evolving 从上到下连接时间为0-无穷 根据点的动态性区分 Static点的数量始终不变 Dynamic点可能消失或出现 Growin是一种特殊的Dynamic，点只能增长 动态网络CUBEtemporal可以在没有连接的情况下存在，但对于evolving等许多网络来说不可以，当连接不存在时，点也就不存在了。三种分类可以形成一个3D的分类图 动态网络模型","link":"/2021/09/13/%E5%8A%A8%E6%80%81%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%BB%BC%E8%BF%B0%E7%AC%94%E8%AE%B0(%E4%B8%80)/"},{"title":"动态图神经网络综述笔记(二)动态图神经网络","text":"笔记第二部分 Dynamic graph neural networks动态图网络有深度的时间序列编码，能将邻居节点聚合起来。 定义如果一个深度表征学习将邻居节点信息聚集起来作为结构，那么这就是一个动态图神经网络在离散的情况下，DGNN是GNN和时间序列的组合。如果是连续的，情况就会有些多变，聚集节点不能再用传统的GNN的方法。 DGNN的种类 Pseudo-dynamic这个方法改变的是网络的拓扑结构，而不是时间。 Discrete编码网络使用了快照，并且每次快照编码一次。 Continuous遍历网络是以边和边的形式，所以它完全独立于任何的快照尺寸。Pserudo-dynamic models pseudo-dynamic contains dynamic processes, but thedynamic properties of the model are not fit to the dynamicdata. 按照我的理解，这种方式只适用于数据不会改变的情况… Edge-weighted models是将动态网络转化为edge-weighted network 然后使用静态的GNN在上面。例如TDGNN Discrete dynamic graph neural networks给出一组离散的图通过GNN形成z代表在时间t中的i节点通过函数f，生成当前的h，f可以是RNN和自注意力机制也可以这样表示：","link":"/2021/09/14/%E5%8A%A8%E6%80%81%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%BB%BC%E8%BF%B0%E7%AC%94%E8%AE%B0-%E4%BA%8C-%E5%8A%A8%E6%80%81%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"title":"通过右移2的幂次实现被除数为负数的除法","text":"在阅读CSAPP的时候，看了练习题3.20的答案，说到被除数为负数的时候需要加偏置。 WHY?总结了一下CSAPP中的解释（书P73）计算机实现除法的时候，需要的时钟周期很长，所以当除数为2的幂次的时候，就可以使用算术右移来实现除法。 被除数非负的情况整数的除法总是舍入到零的，比如2.3舍入到2， -1.5舍入到-1。当被除数为正数的时候，算术右移来执行除法，结果自然是向零舍入的。（因为直接把后面右移的数字舍弃了） 被除数负数的情况但是当被除数是负数的时候，会出现向下舍入，比如-1.5会被舍入为-2。为了解决这个问题，我们需要先对被除数加上一个偏置数。当除数为2的k次幂的时候，偏置量为2^k - 1这样就可以解决被除数为负数的舍入问题。以下为CSAPP中的推导 个人简单理解假设除数为2的k次幂，代表我们要右移k位，当这k位都为0的时候，代表不需要舍入，能够整除，但是当k位有任何一位为1的时候，代表不能整除，需要做舍入处理。如果不加偏置，就代表我们要直接舍弃最低的k位，对不需要右移的最低位毫无影响，那么对于负数来说。如果加上偏置，那么需要舍入的时候，对于第k+1位，会有一个来自低位的进位，这个时候数值自然就会向0舍入。","link":"/2021/07/19/%E9%80%9A%E8%BF%87%E5%8F%B3%E7%A7%BB2%E7%9A%84%E5%B9%82%E6%AC%A1%E5%AE%9E%E7%8E%B0%E9%99%A4%E6%B3%95/"},{"title":"计算机网络笔记3.7","text":"Classic TCP Congestion Control这种方法是当网络拥塞时，TCP减少发送的速率。当网络不拥塞时，TCP增加发送速率。这样就带来三个问题 当遇到网络阻塞时，TCP如何限制发送的速率？ TCP如何感知拥塞？ 当发送方感知到了端对端的拥塞时，应当采用什么算法改变速率？ 前提概念$LastByteRead$ 应用进程从缓存中独处的数据流的最后一个字节的编号$LastByteRcvd$ 从网络中到达的并且已放入主机接受缓存中的数据流最后一个字节的编号$rwnd$为接受窗口，是表明当前缓存中还有多少剩余的空间$$ rwnd = RcvBuffer -[LastByteRcvd - LastByteRead] $$ $ cwnd $ 为拥塞窗口，它对发送方向网络中发送流量的速率进行了限制 TCP发送方限制发送连接流量$ cwnd $ 会对一个TCP发送方能向防落中发送流量的速率进行限制。在一个发送方中未被确认的数据流不会超过$cwnd$和$rwnd$中的最小值。$$ LastByteSent - LastByteAcked \\le min{cwd, rwnd}$$如果rwnd足够大的时候，发送方能发送的未被确认的数据量取决于$cwdn$，所以通过调节$cwdn$的值，就可以调节发送方向它连接发送数据的速率。","link":"/2021/09/15/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%94%E8%AE%B03-7/"},{"title":"记录BUG_孤儿进程","text":"记录bug 今天写多进程的时候遇到了这样一个bug，我通过fork创建子进程，然后再让子进程fork创建子进程…直到一个终止条件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990// #include &quot;kernel/types.h&quot;// #include &quot;kernel/stat.h&quot;// #include &quot;user/user.h&quot;#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;#include &lt;stdlib.h&gt;#include &lt;sys/wait.h&gt;#define READMODE 0#define WRITEMODE 1int main(){ // int primers_array[40]; // for(int i = 2; i &lt;= 35; i++) // primers_array[i] = i; int p[2]; pipe(p); int read_pipe = p[READMODE]; int write_pipe = p[WRITEMODE]; close(0); int pppid = 0; if( (pppid = fork()) == 0) { while(1) { printf(&quot;pid: %d\\n&quot;, getpid()); pipe(p); close(write_pipe); int base_num; if(read(read_pipe, &amp;base_num, sizeof(int)) == 0) { printf(&quot;pid %d 我死了\\n&quot;,getpid()); close(p[READMODE]); close(p[WRITEMODE]); close(read_pipe); exit(0); } printf(&quot;prime %d\\n&quot;, base_num); if(base_num == 31) { close(p[READMODE]); close(p[WRITEMODE]); close(read_pipe); exit(0); } int pid = fork(); if(pid &gt; 0) { close(p[READMODE]); int x; while(read(read_pipe, &amp;x, sizeof(int))) { if(x % base_num != 0) { write(p[WRITEMODE], &amp;x, sizeof(int)); } } close(read_pipe); int status = 0; printf(&quot;pid %d done\\n&quot;, getpid()); exit(0); } else { read_pipe = p[READMODE]; write_pipe = p[WRITEMODE]; } } } else { close(p[READMODE]); for(int i = 2; i &lt;= 35; i++) { write(p[WRITEMODE], &amp;i, sizeof(int)); } close(p[WRITEMODE]); int wpid; int status = 0; printf(&quot;结束了&quot;); exit(0); } exit(0);} 发现最后进程都退出之后，命令行不动，除非输入一些东西或者放大缩小终端界面。。。我目测原因是因为这样链式fork，并且每个父进程都在子进程前面exit，就会导致子进程成为孤儿进程，孤儿进程由init操作系统管理，也就是说，孤儿进程的父进程会变成system，不再是bash，原因应该是最后一个进程exit后，bash没有关于这个进程的信息，所以不会变化…但是具体原因不是很清楚，需要学完操作系统后再看。而且当我使用wait之后，所有父进程都卡住了… An orphan process is a computer process whose parent process has finished or terminated, though it remains running itself. In a Unix-like operating system any orphaned process will be immediately adopted by the special init system process: the kernel sets the parent to init. This operation is called re-parenting and occurs automatically. Even though technically the process has the “init” process as its parent, it is still called an orphan process since the process that originally created it no longer exists. In other systems orphaned processes are immediately terminated by the kernel. In modern Linux systems, an orphan process may be reparented to a “subreaper” process instead of init. update:原因是我没有关闭管道，导致阻塞…还要记得父进程要wait子进程。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;#include &lt;stdlib.h&gt;#include &lt;sys/wait.h&gt;#define READMODE 0#define WRITEMODE 1int main(){ int p[2]; pipe(p); int read_pipe = p[READMODE]; int write_pipe = p[WRITEMODE]; close(0); int pppid = 0; if( (pppid = fork()) == 0) { while(1) { pipe(p); close(write_pipe); int base_num; if(read(read_pipe, &amp;base_num, sizeof(int)) &lt;= 0) { close(p[READMODE]); close(p[WRITEMODE]); close(read_pipe); exit(0); } printf(&quot;prime %d\\n&quot;, base_num); int pid = fork(); if(pid &gt; 0) { close(p[READMODE]); int x; while(read(read_pipe, &amp;x, sizeof(int))) { if(x % base_num != 0) { write(p[WRITEMODE], &amp;x, sizeof(int)); } } close(p[WRITEMODE]); close(read_pipe); wait((int*)0); exit(0); } else { read_pipe = p[READMODE]; write_pipe = p[WRITEMODE]; } } } else { close(p[READMODE]); for(int i = 2; i &lt;= 35; i++) { write(p[WRITEMODE], &amp;i, sizeof(int)); } close(p[WRITEMODE]); wait((int*)0); exit(0); } exit(0);}","link":"/2021/09/19/%E8%AE%B0%E5%BD%95BUG-%E5%AD%A4%E5%84%BF%E8%BF%9B%E7%A8%8B/"},{"title":"栈在虚拟内存和物理内存映射的增长问题","text":"分段为了解决仅仅使用基址和界限寄存器将进程重定位到物理内存区域，会产生大量的空隙，导致内存没有被有效利用。所以产生了分段的概念，在MMU中，不仅仅一对引入基址和界限寄存器，而是给地址空间内的每个逻辑段一对。一段是地址空间里的一个连续定长的区域。并且只有已用的内存才会在物理内存中分配空间。 如何引用段虚拟地址被分为两个部分，第一个部分表示哪个段，第二个部分表示在段内的地址偏移量。如果地址空间内有三个段，那么需要前两位来表示段，剩下的表示偏移。如上图所示，它指明了第一个段中104（十进制）偏移的位置。也有隐式的方法来表示，比如硬件可以通过地址的产生方式来确定段。 虚拟地址的地址转换正向增长的段，其虚拟地址对应的物理地址很好计算。只需要将偏移量加在Base地址上就行。对于栈这种增长方向为负的来说，需要先计算段的最大偏移量，比如现在有要访问的虚拟地址是15KB（以最开始的两个图为例），那么它应该映射到物理内存的27KB位置，这个虚拟地址的二进制形式是 11 1100 0000 0000前两位是段的表示，那么后12位则是偏移量的可用区域，可用区域为 11 0000 0000 0000 到 11 1111 1111 1111（当然哪些真正可用需要看规定的段的大小）那么最大偏移量为4KB($2^{12}$)，由于栈是负增长的，而虚拟地址中的偏移量是表示距离 11 0000 0000 0000的大小，而距离栈的偏移量的Base应该是虚拟地址的偏移量减去4KB，也就是3KB-4KB=-1KB，从而得到27KB。","link":"/2021/09/24/%E6%A0%88%E5%9C%A8%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98%E5%92%8C%E7%89%A9%E7%90%86%E5%86%85%E5%AD%98%E6%98%A0%E5%B0%84%E7%9A%84%E5%A2%9E%E9%95%BF%E9%97%AE%E9%A2%98/"},{"title":"mit 6.S081 Lab2 System Call","text":"做这个实验之前需要把 xvb book 第二章和第四章的 4.3 4.4看了， 有助于理解。 System call tracing实验大意实现trace指令， trace接受mask以及调用的程序和它的参数。mask代表要追踪哪些系统调用，这些都可以在kernel/syscall.h中看到 过程大致思路是通过trace函数将进程中新添加的trace_mask设置好，当syscall调用时，通过trace_mask和被调用的系统调用的mask进行相与，如果大于零，就打印该系统调用的信息。 这个lab已经提供了user/trace.c这个函数，所以不需要自己写，但是需要在user/user.h，user/usys.pl，以及kernel/syscall.h添加声明，还需要在kernel/syscall.c中的函数指针数组中，添加后面需要我们自己在 kernel/sysproc.c添加的sys_trace。 12// user/user.hint trace(int); 12// user/usys.plentry(&quot;trace&quot;); 12// kernel/syscall.h#define SYS_trace 22 12345678910111213141516171819202122232425//kernel/syscall.cstatic uint64 (*syscalls[])(void) = {[SYS_fork] sys_fork,[SYS_exit] sys_exit,[SYS_wait] sys_wait,[SYS_pipe] sys_pipe,[SYS_read] sys_read,[SYS_kill] sys_kill,[SYS_exec] sys_exec,[SYS_fstat] sys_fstat,[SYS_chdir] sys_chdir,[SYS_dup] sys_dup,[SYS_getpid] sys_getpid,[SYS_sbrk] sys_sbrk,[SYS_sleep] sys_sleep,[SYS_uptime] sys_uptime,[SYS_open] sys_open,[SYS_write] sys_write,[SYS_mknod] sys_mknod,[SYS_unlink] sys_unlink,[SYS_link] sys_link,[SYS_mkdir] sys_mkdir,[SYS_close] sys_close,[SYS_trace] sys_trace,//新添加的函数指针，指向sysproc.c中的sys_trace} 然后向kernel/proc.h 中的 struct proc 添加 int trace_mask 1234struct proc { ...... int trace_mask;}; user调用trace时，实际上调用的是sys_trace，所以我们需要添加在 kernei/sysproc.c的sys_trace函数。。 123456789101112131415161718192021222324// kernel/sysproc.c//这里我将主要的函数写在了 kernel/proc.c中uint64sys_trace(void){ int trace_mask = 0; if(argint(0, &amp;trace_mask) &lt; 0)// 通过argint读取调用trace时所传入的参数 return -1; return trace(trace_mask);}//kernel/proc.cint trace(int mask){ struct proc *p = myproc();//获取当前进程 p-&gt;trace_mask = mask;// 将当前进程的trace_mask设置为 mask return 0;}//kernel/defs.h//在proc定义的函数，需要在 defs.h中添加声明，这样sysporc.c中才可以使用//proc.h.......int trace(int); 我们还需要在调用fork生成子进程的时候，将父进程的trace_mask复制给子进程 1np-&gt;trace_mask = p-&gt;trace_mask; 最后需要在syscall中，判断是否被调用的函数包含在mask中，如果包含在mask中，则输出信息，因为输出信息需要输出系统调用的函数名，所以还需要添加一个字符串数组。 123456789101112131415161718192021222324252627282930313233343536373839404142434445kernel/syscall.hchar * fun_name[35]={ &quot;null&quot;,//在函数的mask都是从1开始的，所以null作为占位符。 &quot;fork&quot;, &quot;exit&quot;, &quot;wait&quot;, &quot;pipe&quot;, &quot;read&quot;, &quot;kill&quot;, &quot;exec&quot;, &quot;fstat&quot;, &quot;chdir&quot;, &quot;dup&quot;, &quot;getpid&quot;, &quot;sbrk&quot;, &quot;sleep&quot;, &quot;uptime&quot;, &quot;open&quot;, &quot;write&quot;, &quot;mknod&quot;, &quot;unlink&quot;, &quot;link&quot;, &quot;mkdir&quot;, &quot;close&quot;, &quot;trace&quot;, &quot;sysinfo&quot;};voidsyscall(void){ int num; struct proc *p = myproc(); num = p-&gt;trapframe-&gt;a7; int mask_value = 1 &lt;&lt; num; if(num &gt; 0 &amp;&amp; num &lt; NELEM(syscalls) &amp;&amp; syscalls[num]) { p-&gt;trapframe-&gt;a0 = syscalls[num](); if((mask_value &amp; (p-&gt;trace_mask)) != 0)//如果当前函数的mask在trace_mask中,就打印信息，a0寄存器中包含函数的返回值。 printf(&quot;%d: syscall %s -&gt; %d\\n&quot;, p-&gt;pid, fun_name[num], p-&gt;trapframe-&gt;a0); } else { printf(&quot;%d %s: unknown sys call %d\\n&quot;, p-&gt;pid, p-&gt;name, num); p-&gt;trapframe-&gt;a0 = -1; } 这样我们就完成了lab2的第一个实验。 Sysinfo实验大意实现sysinfo，获取系统中有多少非UNUSED的进程和空闲内存字节数。 过程和上一个system call 实验一样，需要将sysinfo声明在各个文件中，实验介绍中已经给出来了。然后就是获取当前不是UNUSED的进程，比较简单。 1234567891011121314// kernel/proc.cint count_proc(void){ int count = 0; struct proc *p; for(p = proc; p &lt; &amp;proc[NPROC]; p++) //proc是全局变量，是进程的数组，NPROC是进程的个数 { acquire(&amp;p-&gt;lock);// 先给所查询的进程上锁 if(p-&gt;state != UNUSED)// 如果state不是 unused，则count++ count ++; release(&amp;p-&gt;lock); } return count;} 然后就是获取空闲内存字节数， xv6是通过freelist管理的内存，每个页大小为PAGESIZE，相关代码可以参考 kernel/kalloc.c中的kalloc 123456789101112131415161718// Allocate one 4096-byte page of physical memory.// Returns a pointer that the kernel can use.// Returns 0 if the memory cannot be allocated.void *kalloc(void){ struct run *r; acquire(&amp;kmem.lock); r = kmem.freelist; // 获取freelist的头指针 if(r) kmem.freelist = r-&gt;next; //获取一个freelist中的页 release(&amp;kmem.lock); if(r) memset((char*)r, 5, PGSIZE); // fill with junk return (void*)r;} 通过阅读这个代码，就可以知道想计算空闲内存的大小，只需要计算freelist中有多少个页就行了。 1234567891011121314uint64 get_freemem_num(void){ struct run *r; uint64 num = 0; acquire(&amp;kmem.lock);// 上锁 r = kmem.freelist; while(r) { num ++; // 如果当前指针指向的是一个页，num++ r = r-&gt;next; } release(&amp;kmem.lock); return num * PGSIZE; // 通过页的个数 乘上 页的大小来获取内存空闲大小} 至此，我们需要的两个函数就写完了，剩下的就是完成kernel/sysproc.c 中的sysinfo函数了，需要注意的是，当程序调用系统函数的时候，进入的是 kernel mode 无法通过 user mode 中的虚拟地址直接将数据存入虚拟地址所指向的物理地址，因为目前xv6是有一个全局的kernel page table，其中没有每个进程的user table 的映射，所以需要使用copyout来获取指定page table中的物理地址，并将数据存入进去。 1234567891011121314151617181920uint64sys_sysinfo(void){ uint64 st; struct proc *p = myproc(); struct sysinfo info; if(argaddr(0, &amp;st) &lt; 0) { printf(&quot;sys_sysinfo: get addr error\\n&quot;); return -1; } info.freemem = get_freemem_num(); info.nproc = count_proc(); if(copyout(p-&gt;pagetable, st, (char *)&amp;info, sizeof info) &lt; 0) // 获取物理地址，并将info存入其中。 { printf(&quot;sys_sysinfo: copyout error\\n&quot;); return -1; } return 0;} 在添加函数的时候，不要忘记取 defs.h中添加对应的声明。 我们lab2整个就完成了^_^","link":"/2021/10/01/mit-6-S081-Lab2-System-Call/"},{"title":"mit 6.S081 Lab3 page tables","text":"这一次实验需要读xv6 book中的第三章，而且需要好好读… Print a page table实验大意实现vmprint，将指定的page talbe中的信息打印出来 过程xv6中是二级页表，每级page table大小是 page 大小，并且可以容纳512个pte，所以每级Page table 需要在va中占据9位来表明PTE的位置。并且可以使用这个PTE跳转到所需要的Page table的位置。这个实验需要读一下 kernel/vm.c 的walk函数。 12345678910111213141516171819202122232425262728293031// Return the address of the PTE in page table pagetable// that corresponds to virtual address va. If alloc!=0,// create any required page-table pages.//// The risc-v Sv39 scheme has three levels of page-table// pages. A page-table page contains 512 64-bit PTEs.// A 64-bit virtual address is split into five fields:// 39..63 -- must be zero.// 30..38 -- 9 bits of level-2 index.// 21..29 -- 9 bits of level-1 index.// 12..20 -- 9 bits of level-0 index.// 0..11 -- 12 bits of byte offset within the page.pte_t *walk(pagetable_t pagetable, uint64 va, int alloc){ if(va &gt;= MAXVA) panic(&quot;walk&quot;); for(int level = 2; level &gt; 0; level--) { pte_t *pte = &amp;pagetable[PX(level, va)]; if(*pte &amp; PTE_V) { // 如果当且页有效的话 pagetable = (pagetable_t)PTE2PA(*pte); //获取pte中的pa } else { if(!alloc || (pagetable = (pde_t*)kalloc()) == 0) return 0; memset(pagetable, 0, PGSIZE); *pte = PA2PTE(pagetable) | PTE_V; } } return &amp;pagetable[PX(0, va)];} 那么vmprint大体思路就出来了，因为pagetable中有512个pte，我们只需要遍历pte，并且如果pte指向的page 还是page table 那么就递归的调用vmprint就行，这里为了实现递归调用，我们需要一个tool函数。 1234567891011121314151617181920212223242526272829//print ptes and pas from a pagetablevoidvmprint(pagetable_t pagetable){ printf(&quot;page table %p\\n&quot;, pagetable); __vmprint_tool(pagetable, 1);}// a tool function for vmprintvoid__vmprint_tool(pagetable_t pagetable, int depth){ for(int i = 0; i &lt; 512; i++){ pte_t pte = pagetable[i]; if((pte &amp; PTE_V) == 0) continue; for(int j = 0; j &lt; depth; j++)// 根据当前的深度打印.. { if(j != 0) printf(&quot; &quot;); printf(&quot;..&quot;); } printf(&quot;%d: pte %p pa %p\\n&quot;, i, pte, PTE2PA(pte)); if((pte &amp; PTE_V) &amp;&amp; (pte &amp; (PTE_R|PTE_W|PTE_X)) == 0) {//如果一个pte的标志位中，PTE_R,PTE_W,PTE_X都为零，就代表指向的是一个page table __vmprint_tool((pagetable_t) PTE2PA(pte), depth + 1); } }} 最后需要在exec函数中添加一段代码，让系统初始化完成后，执行第一个进程时调用vmprint。 12345// kernel/exec.c if(p-&gt;pid == 1) { vmprint(p-&gt;pagetable); } A kernel page table per process","link":"/2021/10/02/mit-6-S081-Lab3-page-tables/"}],"tags":[{"name":"bug","slug":"bug","link":"/tags/bug/"},{"name":"OS","slug":"OS","link":"/tags/OS/"}],"categories":[]}